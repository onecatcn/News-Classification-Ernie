{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e5c6be4-e393-411d-9ed4-a79a25b02f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T06:14:57.519955Z",
     "iopub.status.busy": "2021-11-16T06:14:57.519553Z",
     "iopub.status.idle": "2021-11-16T06:14:59.705160Z",
     "shell.execute_reply": "2021-11-16T06:14:59.704560Z",
     "shell.execute_reply.started": "2021-11-16T06:14:57.519930Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddle version :  2.2.0\n",
      "paddlehub version :  2.0.4\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddlehub as hub\n",
    "\n",
    "print('paddle version : ', paddle.__version__)\n",
    "print('paddlehub version : ', hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8467b38d-3b1f-4fbd-8113-6e6b5872f384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T06:14:59.706636Z",
     "iopub.status.busy": "2021-11-16T06:14:59.706331Z",
     "iopub.status.idle": "2021-11-16T06:15:17.197015Z",
     "shell.execute_reply": "2021-11-16T06:15:17.196658Z",
     "shell.execute_reply.started": "2021-11-16T06:14:59.706611Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-16 14:15:00,238] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n",
      "W1116 14:15:00.242748  2875 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1116 14:15:00.248580  2875 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baidu's ERNIE, Enhanced Representation through kNowledge IntEgration, max_seq_len=512 when predtrained. The module is executed as paddle.dygraph.\n"
     ]
    }
   ],
   "source": [
    "from paddle.fluid.contrib.model_stat import summary\n",
    "##模型加载\n",
    "model = hub.Module(name=\"ernie\", task='seq-cls', num_classes=14) \n",
    "print(model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c48bec-c7fb-49c3-9683-173a1c95c28c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T06:15:17.203307Z",
     "iopub.status.busy": "2021-11-16T06:15:17.202980Z",
     "iopub.status.idle": "2021-11-16T06:15:19.761950Z",
     "shell.execute_reply": "2021-11-16T06:15:19.761194Z",
     "shell.execute_reply.started": "2021-11-16T06:15:17.203278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/data/data16287\n",
      "thu_news/\n",
      "thu_news/test.txt\n",
      "thu_news/valid.txt\n",
      "thu_news/train.txt\n",
      "总用量 30M\n",
      "-rw-r--r-- 1 aistudio root 3.7M 11月 19  2019 test.txt\n",
      "-rw-r--r-- 1 aistudio root  23M 11月 19  2019 train.txt\n",
      "-rw-r--r-- 1 aistudio root 3.6M 11月 19  2019 valid.txt\n",
      "print the first 3 samples in the validation datasets\n",
      "text_a\tlabel\n",
      "直击特里勾手助小牛反超神鸟发威火箭仍处劣势　　新浪体育讯　北京时间4月16日消息，火箭今天迎来常规赛的收官战。客场挑战达拉斯小牛的比赛将关系到火箭队最终的排名，目前西部的竞争仍然非常激励。尤其是西部第二到第七的六支球队将在今天展开捉对厮杀的情况下，黄蜂、小牛、开拓者以及马刺都有可能是火箭队的下一个对手。以下为本场比赛的精彩瞬间——　　第四节比赛还剩下8分多钟，姚明重新回到场上，但是小牛队的霍里随后在右翼接队友传球后上演一记三分跳投，虽然身体动作已经变形，但是他仍然将球命中，随后基德在弧顶处的一记三分跳投帮助小牛终于将比分反超，火箭在进攻中直接打不开局面，而小牛更是利用特里空切后的一记勾手将比分反超至4分，包括库班在内的所有小牛现场球迷都站起来振臂高呼，而此时阿德尔曼还在场边低头深沉的思索中。　　比赛还剩下最后5分多钟，洛瑞带球突破中被小牛队员犯规，洛瑞来不及刹车让自己直接撞到了观众席上，右腿疼痛难忍的他脸都几乎变形，结果他两罚两中，火箭队还落后两分。随后，洛瑞将球直接传给此时已经回到场上的阿泰，野兽此时将球稳下，并没有急于进攻，随后他顺势将球塞给兰德里，神鸟利用对方站位空隙直接杀到篮下，上篮成功，火箭将比分终于追至80平。场上局面对于火箭来说绝对是不容有失。　　(sabrina)\t体育\n",
      "北京网购年消费额112亿元　　商报讯(记者吴文治)昨日，淘宝网发布的《2009-2010年度中国网购热门城市报告》显示，北京年度网购消费力达112.5亿元，与上海相差近62亿元，位列十大热门消费力城市第二位。此外，男性网购的消费金额高出女性，与“女性是网购主力军”的传统观念不符。　　淘宝公布的报告显示，中国网购消费力十大城市分别是上海、北京、深圳、杭州、广州、南京、苏州、天津、温州和宁波。主要集中在以江浙沪为主的长三角地区、以广深为主的珠三角地区和以北京为主的京津地区。北京年度网购112.5亿元的消费额，占国内城市网购消费额的5.6%。　　中国网购消费力十大城市的消费金额性别来源比例中，男性占比超过了女性。前者占比达到53.5%，后者则为46.5%。不过，在成交人数、成交笔数等关键数据上显示，女性消费者均高于男性。此外，在十大网购热门城市中，25岁-34岁的群体成为网购消费的主力军，占比达到62.49%。\t科技\n",
      "print the last 3 samples in the validation datasets\n",
      "事业测试：你工作易受他人干扰吗(图)　　独家撰稿：苑椿　心理测试征稿启事 欢迎关注新浪星座微博　　办公室永远是个龙蛇混杂、藏龙卧虎的地方，你永远不知道一张张面具底下会是怎样的脸庞，你是否还傻傻的对别人的话听之任之，完全搞乱了自己工作的步调？还是笃定的坚守阵地，从未被谣言动摇分毫？赶紧来测测看吧！　　(本测试仅供娱乐，非专业心理指导。)\t星座\n",
      "趣味测试：你怎么红红火火过春节(图)　　独家撰稿：岚　心理测试征稿启事 欢迎关注新浪星座微博　　红红火火过大年啦，每年的此时你都会如何度过呢？是跟家人爱人在一起还是跟朋友兄弟外出欢聚呢？亦或背起行囊远离嘈杂，无论如何，总会有一种适合你的方式，赶紧来测测看吧！　　(本测试仅供娱乐，非专业心理指导。)\t星座\n",
      "人际测试：你的人际磁场强大吗(图)　　独家撰稿：大智若笨　心理测试征稿启事　　如何在草木皆兵的office里脱颖而出，最好的办法不是到处抱怨也不是埋头工作，而是要加强自己的磁场，让周围的人都被你所感染，如此有影响力，你难道还怕自己不能夺人眼球吗。　　独家撰稿：大智若笨　心理测试征稿启事　　如何在草木皆兵的office里脱颖而出，最好的办法不是到处抱怨也不是埋头工作，而是要加强自己的磁场，让周围的人都被你所感染，如此有影响力，你难道还怕自己不能夺人眼球吗。\t星座\n"
     ]
    }
   ],
   "source": [
    "# 数据集解压缩，并打印验证数据集前3条、后3条数据\n",
    "%cd /home/aistudio/data/data16287/\n",
    "!tar -zxvf thu_news.tar.gz\n",
    "!ls -hl thu_news\n",
    "!echo 'print the first 3 samples in the validation datasets'\n",
    "!head -n 3 thu_news/valid.txt\n",
    "!echo 'print the last 3 samples in the validation datasets'\n",
    "!tail -n 3 thu_news/valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb28039-22f0-4235-8ed5-aad6478052bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T06:15:19.763890Z",
     "iopub.status.busy": "2021-11-16T06:15:19.763346Z",
     "iopub.status.idle": "2021-11-16T06:17:03.065396Z",
     "shell.execute_reply": "2021-11-16T06:17:03.064746Z",
     "shell.execute_reply.started": "2021-11-16T06:15:19.763853Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-16 14:15:19,772] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n",
      "[2021-11-16 14:16:40,215] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n",
      "[2021-11-16 14:16:51,212] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text=主旋律在突破中赢得掌声江青正面形象亮相荧屏　　新中国成立60周年之际，银幕、荧屏、舞台上，各种献礼作品精彩纷呈。这些以历史为依据的艺术作品，或者人性化地展现伟人的性格，或者客观地诠释有争议性的人物，或者不回避历史，较以往艺术创作都有很大突破，而观众也看得非常过瘾。　　文/记者周娴、莫斯其格、张素芹　　很客观《解放》还原“争议”人物　　电视剧《解放》追求全景式展现历史，真实还原人物的宗旨，对很多颇受争议的历史人物做了客观的展现，江青首次以青春美好的正面形象出现在荧屏上。同时，该剧用大量篇幅表现了国民党中一些能征善战的将领，客观描绘了他们的性格特征，展现了他们作为军人的英勇与悲壮。相对于此类作品以往的“脸谱化”表现而言，这是一个突破。　　首次看到江青的正面形象　　在《解放》中，江青30多年来首次以正面形象出现在荧屏上，刚刚踏入解放战争洪流的江青，活泼开朗的性格被重点放大。对丈夫的崇拜和深情，照顾病中周恩来的细心周到，这些情节，都将少女江青的情怀刻画得淋漓尽致。剧情进入到中段，她与毛泽东及女儿的温馨生活场面则成为惨烈战争的调和剂。　　网友意见：《解放》里江青有大量的戏，她看上很纯很天真，这可是第一次啊。只有这样才能显得作品真实可信，应该客观公正地评价每一个人。　　主创回应：导演唐国强说，《解放》是站在唯物主义的历史观上，在特定的革命阶段，展现人物固有性格特征，还原人物的本来面貌。　　林彪与将士高唱军歌　　林彪是一代军事家，十大元帅中最年轻的元帅。10年前《大决战》中，首度出现林彪的正面形象，运筹帷幄，决胜千里。《解放》中，又让观众看到了林彪与将士们一起高唱“向前向前向前，我们的队伍向太阳”的景象，看到了一个更加不一样的林彪。　　网友意见：解放战争林彪功不可没，电视剧应该好好表现他。“千秋功罪，自有后人评说”。《解放》对林彪有了比较客观的评价，演员的诠释也相当出色，完全表现出一个具有卓越军事才能、个性孤僻又服从大局的军事家的感觉。　　主创回应：林彪的饰演者由立平说，为了接近林彪的身材，本来体重就不足130斤的我还是咬牙减去了10斤。保持在这个体重我心里才踏实，不光形体像了，而且通过减肥，似乎更能感受到他当时的内心压力。我对军事家有着独特的情感，我的这份情感不单单是向一个人，而是向整个老一辈军事家——致敬！　　国民党将领的铁骨柔情　　剧情进入中段后，《解放》将大量笔墨放在了描写战争中的传奇将领上。张灵甫形象英俊，气质儒雅，是国民党陆军中将、抗日名将，蒋介石对其厚爱有加。他死于国共内战时期的孟良崮战役，孟良崮战役中，对张灵甫采用了正面而又全面的描述，突出了他高傲忠诚的性格，也表现了下属对他的爱戴。　　“干城之将”陈明仁是另一个被正面渲染的国民党将领。“四平之战”中，陈明仁的坚毅、英勇与调兵遣将的能力得到了最好的展现，性格刚烈，悲情又悲壮。　　网友意见：《解放》胜在细节，陈明仁剃发明志和拼死一搏之前留下遗书的段落，已超越了国共战争的敌我界限，成为一个中国军人铁骨柔情的最佳诠释。　　主创回应：唐国强说：“越是客观，便越能感受到伟大。《解放》更注重还原历史，它甚至比《建国大业》更写实，我相信这是最能打动观众的。”　　人性化《建国大业》鲜活伟人　　在以往讲述领袖的影视作品中，领袖形象都会被塑造得笑容可掬、和蔼可亲，但在影片《建国大业》中毛泽东烟不离手，周恩来发起了脾气，几个领袖在一起醉酒唱歌，这些细节完全摆脱了以往主旋律作品中领袖人物概念化的形象，从细节还原了一个个有七情六欲人性化的领袖形象。　　场景一：怒发冲冠　　得知冯玉祥在海上遇难后，毛泽东气得踢翻了水盆，周恩来更大骂手下“都是猪脑袋”，“你们谁能负这个责”，不仅摔了文件夹，还摔了茶杯，连衣服都迸开了。　　网友意见：这是《建国大业》中对周恩来的刻画最有力的一笔，“以前对总理的印象总停留在‘温文尔雅’四个字上，原来总理也跟普通人一样是有脾气的。”“主席突然踢翻了洗脚盆，哐的一声，吓我一跳。但想想，又很符合逻辑。”　　主创说法：周恩来的扮演者刘劲说：“领袖也有喜怒哀乐，导演告诉我，放开演，要表现得怒发冲冠，这就突破了领袖人物顾全大局、和蔼可亲的固有形象，使人物显得更加真实可信。　　场景二：醉酒当歌　　接到淮海战役胜利捷报的当晚，中央四位领导人喝酒庆祝，周恩来揽着朱德、刘少奇高唱《国际歌》，喝醉了的毛泽东歪倒在一旁咧嘴直笑，这样“奔放”的中共领袖在以前的主旋律影片中绝无仅有。　　网友意见：影片的这一段拍得相当感人，不少网友留言称被这个场景感动落泪，“我觉得这是影片最叫人难忘的一幕，我一大老爷们也跟着唱起来了，同时眼眶也湿润了……”“从这一段中能体会领导人的真性情，给人一种亲近感。”　　主创回应：在以往的主旋律电影里没有出现过这种有“丑化”领导人嫌疑的镜头。黄建新解释说，这一段的确是艺术发挥，经过剧组讨论，觉得这样更能显示出领导人在“天下初定”时的那种畅快和浪漫的革命情感，而这一段落在审查时，同样没有收到任何修改建议。　　场景三：“有气无力”喊口号　　《建国大业》中最令人觉得意外的地方，莫过于结尾时毛主席在政协会议上发言，结束时所喊的口号“中华人民共和国万岁”、“联合政府万岁”等。按照以往主旋律电影的处理方式，这种口号无疑要喊得一个比一个响亮，但唐国强扮演的毛泽东，在这里的处理却是一个比一个声音弱，显得有些“有气无力”。　　网友意见：以往的主旋律影片中，主席都是慷慨激昂地喊口号，振奋人心，想不通《建国大业》为什么要这样处理。　　主创回应：导演黄建新解释说，这是唐国强自己提出来的，因为他们在研究了历史上毛主席的演讲录音，发现当年毛主席就是这样的口气，“其实最重要的不是语气，而是毛主席演讲完毕之后，慢慢抬头环顾现场。以往他演讲都是对党内人士，这一次是真正面对全中国在政治方面最有影响力的人。他最后的表情，可谓意味深长。”　　场景四：主席遭轰炸　　毛主席在河北城南庄被潜伏特务告密，蒋介石派两架飞机轰炸城南庄。毛主席当时吃了安眠药刚睡下，警卫员一起抬着担架转移身穿睡衣的主席，最终化险为夷。　　网友意见：这一段惊险、紧张，意外的是主席“临危不乱”的时候居然身穿睡衣！　　主创回应：导演黄建新解释：“这次突破地方就是想让镜头深入到这些历史人物的内心，希望带来新鲜感。”　　不回避　　《复兴之路》用4分钟讲述“文革”　　大型音乐舞蹈史诗《复兴之路》，是继《东方红》、《中国革命之歌》之后，中国文化艺术史上的又一部大型音乐舞蹈史诗。在两个半小时的演出中，八一电影制片厂副厂长刘星创作的朗诵诗《沉思与抉择》用诗歌朗诵的方式讲述了“文革”的十年历史，时间长约4分钟，这也是第一次在中国庆典舞台上涉及“文革”话题。　　场景：首次涉及“文革”　　“如果不是为寻找历史是在哪里转弯，如果不是为寻找民族复兴新的起点，谁还愿意揭开往日的伤口，谁还想回首那曾经的劫难……”在这首诗中，没有出现“文革”的字眼，但是，隐喻、象征的手法，使得交代明确、措辞得体。结尾的处理更是“神来之笔”———原本雷声滚滚、乌云遮空的天空明朗起来，“人们听到中国共产党人的浩然之声，又一次在大地和天空间回旋。”　　网友意见：　　《复兴之路》“结合历史，紧跟时代，用音乐、舞蹈、朗诵、合唱等表演形式，用两个半小时的时间，浓缩了169年的中国历史。这是一次心灵的洗礼，激起了人们的情感共鸣。是最为完美的精彩演出。”　　主创回应：　　对于“文革”等历史细节的出现，文化部部长蔡武接受媒体采访时表示，《复兴之路》涉及这段历史是“因为如果没有对‘文化大革命’这一段的一个交代、一个表现，那么人们就会问，那么三中全会的意义在什么地方，为什么它是一个历史的转折，为什么它提出了改革开放的政策，它的针对性是什么，就是要讲清楚这个问题所以必须要讲到‘文化大革命’，所以我们不回避这个问题，但是我们又不去渲染它”。　　诗作者刘星严格遵循“不回避，不渲染”的创作原则，但用何种方式展开叙述，让他冥思苦想了几个月，直到想到了古典诗词中“比兴”的艺术手法。他接受采访的时候表示：“这二十几行诗，我改了二十多遍。阎肃老师也帮助我一起改写，经常为一两个字绞尽脑汁。我们共同把这个任务完成好”。　　《复兴之路》的总导演张继刚在接受采访的时候表示，对历史上的事情的态度应该是不回避也不渲染，而也正是因为这段历史、一系列的曲折，“让我们更珍惜此时此刻——中国历史上最好的时期”。　　诗歌朗诵的表演者瞿弦和接受采访的时候称，他们这代人都经历了“文革”，在“文革”中有着不同的遭遇，在每个人一生中都留下了不可磨灭的记忆，所以作为表演者要“用自己的体会来感悟，来体现我们多么珍惜这个转折”。\tlabel=娱乐\n",
      "text=骑士总经理位置恐难保布朗下课后首发声明谢球队　　新浪体育讯　北京时间5月27日消息，自从被骑士解雇后，迈克-布朗还未在公开场合发表过任何言论。但当地时间周三，布朗委托骑士对外发表了一份声明，并在声明中感谢克利夫兰给了他这次执教NBA球队的经历。在文章的最后，布朗甚至还动情的表示，过去在骑士队中的5年，对于他来说有着“特殊的经历”。　　布朗在声明中写道：“我为在克利夫兰拥有5年的执教经历感到骄傲。很荣幸能与这么多尊重我的球员和员工共事，我很享受和他们在一起奋斗的时光。同时，我还要感谢球队老板丹-吉尔伯特对我的奉献和鼎力支持。虽然直到我告别这支球队时，我仍然没有为这座城市带来他们想要的东西，但我仍然对在这里的执教成绩感到满意和自豪。”　　在过去的两个赛季中，布朗率领的骑士共赢得了127场常规赛的胜利。而布朗本人也曾经在2009年凭借优异的率队成绩，荣膺NBA联盟最佳教练员称号。而布朗带领骑士所取得的最好成绩，当属2007年闯入最终的总决赛。　　在被骑士解雇之后，布朗一直赋闲在家。不过也许在不久之后，布朗就将迎来下一份主教练的工作。因为在目前联盟的30支球队中，仍然有5支球队在为新赛季主教练的人选发愁，而布朗也极有可能成为这5支球队选帅的潜在目标。　　而据《克利夫兰平原经销商》报道，解雇布朗之后，并不意味着骑士内部的人员调整就此告一段落，反之随着布朗的下课，球队总经理丹尼-费里的前景也变得扑朔迷离。而一旦费里离开，那球队总经理的职位，就将由骑士助理教练克里斯-格兰特接替。　　费里的合同6月30日就将到期，不过从解雇布朗的举动来看，费里也极有可能选择继续留守克利夫兰。而一旦费里最终留任，那毫无疑问，骑士最重要的事情就是尽可能地留下“小皇帝”勒布朗-詹姆斯。　　(小林)\tlabel=体育\n",
      "text=国足11月西亚行会中超老友鲁能新援鸿门宴意欲何为　　记者张远济南报道由于在亚洲杯预赛上，中国和黎巴嫩同在D组，11月14日和22日，中国队将先客后主迎战黎巴嫩。小组赛前两场黎巴嫩一分未得，出线希望渺茫，对此安塔尔并不太在意，他更关注鲁能的队友谁有可能进入国家队，“在我看来，至少有4名队员可以进入国家队，如果他们到时候能到叙利亚比赛，对我来说那别提是一件多么开心的事情了，到时候我会邀请他们品尝叙利亚的美味，也许会请他们到我家做客，我很乐意在厨房里露上一手。”　　安塔尔的哥哥菲塞尔也是一名职业球员，“他在黎巴嫩国家队打左边后卫，到比赛时他也会来，我和哥哥一起代表黎巴嫩，鲁能的队友代表中国，这一定很有趣。”安塔尔这样说并不意味着他放弃了亚洲杯出线的希望，“我们前两场比赛都输了，形势不妙，但我们不会轻易放弃，对中国队的比赛一定会全力以赴。”　　安塔尔说，他最希望黎巴嫩和中国队携手出线，但这实现的可能性几乎为零。“但不管怎么说，过去的8年时间里，我为我的国家付出了努力，我打进了28个进球，我认为自己的成就非常值得骄傲，将来在鲁能，我也期待能够用自己的努力为球队带来荣誉。”\tlabel=体育\n"
     ]
    }
   ],
   "source": [
    "## 数据集加载\n",
    "import os, io, csv\n",
    "from paddlehub.datasets.base_nlp_dataset import InputExample, TextClassificationDataset\n",
    "\n",
    "DATA_DIR=\"/home/aistudio/data/data16287/thu_news\"\n",
    "class ThuNews(TextClassificationDataset):\n",
    "    def __init__(self, tokenizer, mode='train', max_seq_len=128):\n",
    "        if mode == 'train':\n",
    "            data_file = 'train.txt'\n",
    "        elif mode == 'test':\n",
    "            data_file = 'test.txt'\n",
    "        else:\n",
    "            data_file = 'valid.txt'\n",
    "        super(ThuNews, self).__init__(\n",
    "            base_path=DATA_DIR,\n",
    "            data_file=data_file,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_len=max_seq_len,\n",
    "            mode=mode,\n",
    "            is_file_with_header=True,\n",
    "            label_list=['体育', '科技', '社会', '娱乐', '股票', '房产', '教育', '时政', '财经', '星座', '游戏', '家居', '彩票', '时尚'])\n",
    "\n",
    "    # 解析文本文件里的样本\n",
    "    def _read_file(self, input_file, is_file_with_header: bool = False):\n",
    "        if not os.path.exists(input_file):\n",
    "            raise RuntimeError(\"The file {} is not found.\".format(input_file))\n",
    "        else:\n",
    "            with io.open(input_file, \"r\", encoding=\"UTF-8\") as f:\n",
    "                reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)\n",
    "                examples = []\n",
    "                seq_id = 0\n",
    "                header = next(reader) if is_file_with_header else None\n",
    "                for line in reader:\n",
    "                    example = InputExample(guid=seq_id, text_a=line[0], label=line[1])\n",
    "                    seq_id += 1\n",
    "                    examples.append(example)\n",
    "                return examples\n",
    "\n",
    "train_dataset = ThuNews(model.get_tokenizer(), mode='train', max_seq_len=128)\n",
    "dev_dataset = ThuNews(model.get_tokenizer(), mode='dev', max_seq_len=128)\n",
    "test_dataset = ThuNews(model.get_tokenizer(), mode='test', max_seq_len=128)\n",
    "#打印测试集train.txt的前三个样本内容\n",
    "for e in train_dataset.examples[:3]:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c20b48ee-c973-4ce3-bd85-997a2c7ebc37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T06:17:03.066939Z",
     "iopub.status.busy": "2021-11-16T06:17:03.066447Z",
     "iopub.status.idle": "2021-11-16T06:28:28.454971Z",
     "shell.execute_reply": "2021-11-16T06:28:28.454262Z",
     "shell.execute_reply.started": "2021-11-16T06:17:03.066907Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-16 14:17:03,071] [    INFO] - PaddleHub model checkpoint loaded. current_epoch=3 [acc=0.9021]\n",
      "[2021-11-16 14:17:20,409] [   TRAIN] - Epoch=4/3, Step=10/282 loss=0.0572 acc=0.9812 lr=0.000050 step/sec=0.89 | ETA 00:15:52\n",
      "[2021-11-16 14:17:27,611] [   TRAIN] - Epoch=4/3, Step=20/282 loss=0.0682 acc=0.9812 lr=0.000050 step/sec=1.39 | ETA 00:13:00\n",
      "[2021-11-16 14:17:34,829] [   TRAIN] - Epoch=4/3, Step=30/282 loss=0.0546 acc=0.9875 lr=0.000050 step/sec=1.39 | ETA 00:12:04\n",
      "[2021-11-16 14:17:42,041] [   TRAIN] - Epoch=4/3, Step=40/282 loss=0.0217 acc=0.9938 lr=0.000050 step/sec=1.39 | ETA 00:11:35\n",
      "[2021-11-16 14:17:49,255] [   TRAIN] - Epoch=4/3, Step=50/282 loss=0.0494 acc=0.9906 lr=0.000050 step/sec=1.39 | ETA 00:11:18\n",
      "[2021-11-16 14:17:56,454] [   TRAIN] - Epoch=4/3, Step=60/282 loss=0.0917 acc=0.9812 lr=0.000050 step/sec=1.39 | ETA 00:11:07\n",
      "[2021-11-16 14:18:03,684] [   TRAIN] - Epoch=4/3, Step=70/282 loss=0.0696 acc=0.9844 lr=0.000050 step/sec=1.38 | ETA 00:10:59\n",
      "[2021-11-16 14:18:10,933] [   TRAIN] - Epoch=4/3, Step=80/282 loss=0.0659 acc=0.9812 lr=0.000050 step/sec=1.38 | ETA 00:10:53\n",
      "[2021-11-16 14:18:18,145] [   TRAIN] - Epoch=4/3, Step=90/282 loss=0.0671 acc=0.9812 lr=0.000050 step/sec=1.39 | ETA 00:10:48\n",
      "[2021-11-16 14:18:25,354] [   TRAIN] - Epoch=4/3, Step=100/282 loss=0.0301 acc=0.9969 lr=0.000050 step/sec=1.39 | ETA 00:10:44\n",
      "[2021-11-16 14:18:32,567] [   TRAIN] - Epoch=4/3, Step=110/282 loss=0.0251 acc=0.9938 lr=0.000050 step/sec=1.39 | ETA 00:10:41\n",
      "[2021-11-16 14:18:39,790] [   TRAIN] - Epoch=4/3, Step=120/282 loss=0.0683 acc=0.9844 lr=0.000050 step/sec=1.38 | ETA 00:10:39\n",
      "[2021-11-16 14:18:47,022] [   TRAIN] - Epoch=4/3, Step=130/282 loss=0.0386 acc=0.9938 lr=0.000050 step/sec=1.38 | ETA 00:10:36\n",
      "[2021-11-16 14:18:54,241] [   TRAIN] - Epoch=4/3, Step=140/282 loss=0.0245 acc=0.9938 lr=0.000050 step/sec=1.39 | ETA 00:10:35\n",
      "[2021-11-16 14:19:01,465] [   TRAIN] - Epoch=4/3, Step=150/282 loss=0.0618 acc=0.9844 lr=0.000050 step/sec=1.38 | ETA 00:10:33\n",
      "[2021-11-16 14:19:08,702] [   TRAIN] - Epoch=4/3, Step=160/282 loss=0.0383 acc=0.9906 lr=0.000050 step/sec=1.38 | ETA 00:10:32\n",
      "[2021-11-16 14:19:15,932] [   TRAIN] - Epoch=4/3, Step=170/282 loss=0.0392 acc=0.9938 lr=0.000050 step/sec=1.38 | ETA 00:10:30\n",
      "[2021-11-16 14:19:23,144] [   TRAIN] - Epoch=4/3, Step=180/282 loss=0.0467 acc=0.9875 lr=0.000050 step/sec=1.39 | ETA 00:10:29\n",
      "[2021-11-16 14:19:30,348] [   TRAIN] - Epoch=4/3, Step=190/282 loss=0.0633 acc=0.9781 lr=0.000050 step/sec=1.39 | ETA 00:10:28\n",
      "[2021-11-16 14:19:37,563] [   TRAIN] - Epoch=4/3, Step=200/282 loss=0.0242 acc=0.9969 lr=0.000050 step/sec=1.39 | ETA 00:10:27\n",
      "[2021-11-16 14:19:44,780] [   TRAIN] - Epoch=4/3, Step=210/282 loss=0.0987 acc=0.9781 lr=0.000050 step/sec=1.39 | ETA 00:10:26\n",
      "[2021-11-16 14:19:52,000] [   TRAIN] - Epoch=4/3, Step=220/282 loss=0.0433 acc=0.9875 lr=0.000050 step/sec=1.39 | ETA 00:10:26\n",
      "[2021-11-16 14:19:59,207] [   TRAIN] - Epoch=4/3, Step=230/282 loss=0.0281 acc=0.9906 lr=0.000050 step/sec=1.39 | ETA 00:10:25\n",
      "[2021-11-16 14:20:06,426] [   TRAIN] - Epoch=4/3, Step=240/282 loss=0.0628 acc=0.9875 lr=0.000050 step/sec=1.39 | ETA 00:10:24\n",
      "[2021-11-16 14:20:13,649] [   TRAIN] - Epoch=4/3, Step=250/282 loss=0.0452 acc=0.9781 lr=0.000050 step/sec=1.38 | ETA 00:10:24\n",
      "[2021-11-16 14:20:20,872] [   TRAIN] - Epoch=4/3, Step=260/282 loss=0.0445 acc=0.9875 lr=0.000050 step/sec=1.38 | ETA 00:10:23\n",
      "[2021-11-16 14:20:28,101] [   TRAIN] - Epoch=4/3, Step=270/282 loss=0.0814 acc=0.9750 lr=0.000050 step/sec=1.38 | ETA 00:10:23\n",
      "[2021-11-16 14:20:35,304] [   TRAIN] - Epoch=4/3, Step=280/282 loss=0.0920 acc=0.9781 lr=0.000050 step/sec=1.39 | ETA 00:10:22\n",
      "[2021-11-16 14:20:47,941] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - [Evaluation result] avg_acc=0.9086\n",
      "[2021-11-16 14:20:58,686] [    EVAL] - Saving best model to ./ckpt/best_model [best acc=0.9086]\n",
      "[2021-11-16 14:20:58,689] [    INFO] - Saving model checkpoint to ./ckpt/epoch_4\n",
      "[2021-11-16 14:21:08,858] [   TRAIN] - Epoch=5/3, Step=10/282 loss=0.0484 acc=0.9875 lr=0.000050 step/sec=0.36 | ETA 00:11:34\n",
      "[2021-11-16 14:21:16,078] [   TRAIN] - Epoch=5/3, Step=20/282 loss=0.0175 acc=1.0000 lr=0.000050 step/sec=1.38 | ETA 00:11:31\n",
      "[2021-11-16 14:21:23,283] [   TRAIN] - Epoch=5/3, Step=30/282 loss=0.0768 acc=0.9781 lr=0.000050 step/sec=1.39 | ETA 00:11:29\n",
      "[2021-11-16 14:21:30,512] [   TRAIN] - Epoch=5/3, Step=40/282 loss=0.0758 acc=0.9844 lr=0.000050 step/sec=1.38 | ETA 00:11:26\n",
      "[2021-11-16 14:21:37,730] [   TRAIN] - Epoch=5/3, Step=50/282 loss=0.0261 acc=0.9906 lr=0.000050 step/sec=1.39 | ETA 00:11:24\n",
      "[2021-11-16 14:21:44,964] [   TRAIN] - Epoch=5/3, Step=60/282 loss=0.0410 acc=0.9906 lr=0.000050 step/sec=1.38 | ETA 00:11:22\n",
      "[2021-11-16 14:21:52,341] [   TRAIN] - Epoch=5/3, Step=70/282 loss=0.0598 acc=0.9812 lr=0.000050 step/sec=1.36 | ETA 00:11:20\n",
      "[2021-11-16 14:21:59,558] [   TRAIN] - Epoch=5/3, Step=80/282 loss=0.0372 acc=0.9906 lr=0.000050 step/sec=1.39 | ETA 00:11:18\n",
      "[2021-11-16 14:22:06,776] [   TRAIN] - Epoch=5/3, Step=90/282 loss=0.0558 acc=0.9875 lr=0.000050 step/sec=1.39 | ETA 00:11:16\n",
      "[2021-11-16 14:22:13,987] [   TRAIN] - Epoch=5/3, Step=100/282 loss=0.0153 acc=0.9969 lr=0.000050 step/sec=1.39 | ETA 00:11:15\n",
      "[2021-11-16 14:22:21,210] [   TRAIN] - Epoch=5/3, Step=110/282 loss=0.0595 acc=0.9812 lr=0.000050 step/sec=1.38 | ETA 00:11:13\n",
      "[2021-11-16 14:22:28,434] [   TRAIN] - Epoch=5/3, Step=120/282 loss=0.0416 acc=0.9844 lr=0.000050 step/sec=1.38 | ETA 00:11:11\n",
      "[2021-11-16 14:22:35,655] [   TRAIN] - Epoch=5/3, Step=130/282 loss=0.0262 acc=0.9969 lr=0.000050 step/sec=1.38 | ETA 00:11:10\n",
      "[2021-11-16 14:22:42,885] [   TRAIN] - Epoch=5/3, Step=140/282 loss=0.0233 acc=0.9938 lr=0.000050 step/sec=1.38 | ETA 00:11:09\n",
      "[2021-11-16 14:22:50,125] [   TRAIN] - Epoch=5/3, Step=150/282 loss=0.0214 acc=0.9938 lr=0.000050 step/sec=1.38 | ETA 00:11:07\n",
      "[2021-11-16 14:22:57,363] [   TRAIN] - Epoch=5/3, Step=160/282 loss=0.0409 acc=0.9875 lr=0.000050 step/sec=1.38 | ETA 00:11:06\n",
      "[2021-11-16 14:23:04,551] [   TRAIN] - Epoch=5/3, Step=170/282 loss=0.0353 acc=0.9844 lr=0.000050 step/sec=1.39 | ETA 00:11:05\n",
      "[2021-11-16 14:23:11,773] [   TRAIN] - Epoch=5/3, Step=180/282 loss=0.0572 acc=0.9812 lr=0.000050 step/sec=1.38 | ETA 00:11:04\n",
      "[2021-11-16 14:23:19,000] [   TRAIN] - Epoch=5/3, Step=190/282 loss=0.0451 acc=0.9875 lr=0.000050 step/sec=1.38 | ETA 00:11:02\n",
      "[2021-11-16 14:23:26,229] [   TRAIN] - Epoch=5/3, Step=200/282 loss=0.0845 acc=0.9875 lr=0.000050 step/sec=1.38 | ETA 00:11:01\n",
      "[2021-11-16 14:23:33,443] [   TRAIN] - Epoch=5/3, Step=210/282 loss=0.0345 acc=0.9906 lr=0.000050 step/sec=1.39 | ETA 00:11:00\n",
      "[2021-11-16 14:23:40,639] [   TRAIN] - Epoch=5/3, Step=220/282 loss=0.0228 acc=0.9906 lr=0.000050 step/sec=1.39 | ETA 00:10:59\n",
      "[2021-11-16 14:23:47,844] [   TRAIN] - Epoch=5/3, Step=230/282 loss=0.0445 acc=0.9906 lr=0.000050 step/sec=1.39 | ETA 00:10:58\n",
      "[2021-11-16 14:23:55,061] [   TRAIN] - Epoch=5/3, Step=240/282 loss=0.0175 acc=0.9906 lr=0.000050 step/sec=1.39 | ETA 00:10:57\n",
      "[2021-11-16 14:24:02,284] [   TRAIN] - Epoch=5/3, Step=250/282 loss=0.0420 acc=0.9938 lr=0.000050 step/sec=1.38 | ETA 00:10:56\n",
      "[2021-11-16 14:24:09,504] [   TRAIN] - Epoch=5/3, Step=260/282 loss=0.0140 acc=0.9938 lr=0.000050 step/sec=1.39 | ETA 00:10:56\n",
      "[2021-11-16 14:24:16,735] [   TRAIN] - Epoch=5/3, Step=270/282 loss=0.0096 acc=1.0000 lr=0.000050 step/sec=1.38 | ETA 00:10:55\n",
      "[2021-11-16 14:24:23,956] [   TRAIN] - Epoch=5/3, Step=280/282 loss=0.0396 acc=0.9875 lr=0.000050 step/sec=1.38 | ETA 00:10:54\n",
      "[2021-11-16 14:24:36,575] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - [Evaluation result] avg_acc=0.9250\n",
      "[2021-11-16 14:24:47,192] [    EVAL] - Saving best model to ./ckpt/best_model [best acc=0.9250]\n",
      "[2021-11-16 14:24:47,195] [    INFO] - Saving model checkpoint to ./ckpt/epoch_5\n",
      "[2021-11-16 14:24:57,846] [   TRAIN] - Epoch=6/3, Step=10/282 loss=0.0334 acc=0.9844 lr=0.000050 step/sec=0.35 | ETA 00:11:30\n",
      "[2021-11-16 14:25:05,046] [   TRAIN] - Epoch=6/3, Step=20/282 loss=0.0155 acc=0.9938 lr=0.000050 step/sec=1.39 | ETA 00:11:29\n",
      "[2021-11-16 14:25:12,263] [   TRAIN] - Epoch=6/3, Step=30/282 loss=0.0122 acc=0.9969 lr=0.000050 step/sec=1.39 | ETA 00:11:28\n",
      "[2021-11-16 14:25:19,477] [   TRAIN] - Epoch=6/3, Step=40/282 loss=0.0089 acc=1.0000 lr=0.000050 step/sec=1.39 | ETA 00:11:26\n",
      "[2021-11-16 14:25:26,717] [   TRAIN] - Epoch=6/3, Step=50/282 loss=0.0117 acc=0.9969 lr=0.000050 step/sec=1.38 | ETA 00:11:25\n",
      "[2021-11-16 14:25:33,943] [   TRAIN] - Epoch=6/3, Step=60/282 loss=0.0046 acc=1.0000 lr=0.000050 step/sec=1.38 | ETA 00:11:24\n",
      "[2021-11-16 14:25:41,158] [   TRAIN] - Epoch=6/3, Step=70/282 loss=0.0219 acc=0.9938 lr=0.000050 step/sec=1.39 | ETA 00:11:23\n",
      "[2021-11-16 14:25:48,373] [   TRAIN] - Epoch=6/3, Step=80/282 loss=0.0156 acc=0.9938 lr=0.000050 step/sec=1.39 | ETA 00:11:22\n",
      "[2021-11-16 14:25:55,592] [   TRAIN] - Epoch=6/3, Step=90/282 loss=0.0247 acc=0.9906 lr=0.000050 step/sec=1.39 | ETA 00:11:20\n",
      "[2021-11-16 14:26:02,825] [   TRAIN] - Epoch=6/3, Step=100/282 loss=0.0171 acc=0.9875 lr=0.000050 step/sec=1.38 | ETA 00:11:19\n",
      "[2021-11-16 14:26:10,049] [   TRAIN] - Epoch=6/3, Step=110/282 loss=0.0390 acc=0.9906 lr=0.000050 step/sec=1.38 | ETA 00:11:18\n",
      "[2021-11-16 14:26:17,268] [   TRAIN] - Epoch=6/3, Step=120/282 loss=0.0136 acc=0.9938 lr=0.000050 step/sec=1.39 | ETA 00:11:17\n",
      "[2021-11-16 14:26:24,493] [   TRAIN] - Epoch=6/3, Step=130/282 loss=0.0188 acc=0.9969 lr=0.000050 step/sec=1.38 | ETA 00:11:16\n",
      "[2021-11-16 14:26:31,715] [   TRAIN] - Epoch=6/3, Step=140/282 loss=0.0429 acc=0.9875 lr=0.000050 step/sec=1.38 | ETA 00:11:16\n",
      "[2021-11-16 14:26:38,935] [   TRAIN] - Epoch=6/3, Step=150/282 loss=0.0184 acc=0.9938 lr=0.000050 step/sec=1.38 | ETA 00:11:15\n",
      "[2021-11-16 14:26:46,165] [   TRAIN] - Epoch=6/3, Step=160/282 loss=0.0324 acc=0.9906 lr=0.000050 step/sec=1.38 | ETA 00:11:14\n",
      "[2021-11-16 14:26:53,378] [   TRAIN] - Epoch=6/3, Step=170/282 loss=0.0068 acc=0.9969 lr=0.000050 step/sec=1.39 | ETA 00:11:13\n",
      "[2021-11-16 14:27:00,601] [   TRAIN] - Epoch=6/3, Step=180/282 loss=0.0316 acc=0.9938 lr=0.000050 step/sec=1.38 | ETA 00:11:12\n",
      "[2021-11-16 14:27:07,815] [   TRAIN] - Epoch=6/3, Step=190/282 loss=0.0173 acc=0.9938 lr=0.000050 step/sec=1.39 | ETA 00:11:11\n",
      "[2021-11-16 14:27:15,032] [   TRAIN] - Epoch=6/3, Step=200/282 loss=0.0332 acc=0.9906 lr=0.000050 step/sec=1.39 | ETA 00:11:10\n",
      "[2021-11-16 14:27:22,248] [   TRAIN] - Epoch=6/3, Step=210/282 loss=0.0186 acc=0.9906 lr=0.000050 step/sec=1.39 | ETA 00:11:10\n",
      "[2021-11-16 14:27:29,469] [   TRAIN] - Epoch=6/3, Step=220/282 loss=0.0191 acc=0.9969 lr=0.000050 step/sec=1.38 | ETA 00:11:09\n",
      "[2021-11-16 14:27:36,711] [   TRAIN] - Epoch=6/3, Step=230/282 loss=0.0140 acc=0.9969 lr=0.000050 step/sec=1.38 | ETA 00:11:08\n",
      "[2021-11-16 14:27:43,926] [   TRAIN] - Epoch=6/3, Step=240/282 loss=0.0258 acc=0.9969 lr=0.000050 step/sec=1.39 | ETA 00:11:07\n",
      "[2021-11-16 14:27:51,137] [   TRAIN] - Epoch=6/3, Step=250/282 loss=0.0387 acc=0.9906 lr=0.000050 step/sec=1.39 | ETA 00:11:07\n",
      "[2021-11-16 14:27:58,365] [   TRAIN] - Epoch=6/3, Step=260/282 loss=0.0052 acc=1.0000 lr=0.000050 step/sec=1.38 | ETA 00:11:06\n",
      "[2021-11-16 14:28:05,591] [   TRAIN] - Epoch=6/3, Step=270/282 loss=0.0290 acc=0.9875 lr=0.000050 step/sec=1.38 | ETA 00:11:05\n",
      "[2021-11-16 14:28:12,823] [   TRAIN] - Epoch=6/3, Step=280/282 loss=0.0377 acc=0.9906 lr=0.000050 step/sec=1.38 | ETA 00:11:05\n",
      "[2021-11-16 14:28:25,448] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - [Evaluation result] avg_acc=0.9143\n",
      "[2021-11-16 14:28:25,451] [    INFO] - Saving model checkpoint to ./ckpt/epoch_6\n"
     ]
    }
   ],
   "source": [
    "## 迁移学习训练，本次为第二次训练，每次训练有3epochs\n",
    "lert=5e-5\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=lert, parameters=model.parameters())\n",
    "trainer = hub.Trainer(model, optimizer, checkpoint_dir='./ckpt', use_gpu=True)\n",
    "trainer.train(train_dataset, epochs=3, batch_size=32, eval_dataset=dev_dataset, save_interval=1)   # 配置训练参数，启动训练，并指定验证集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b198c98-8bd5-4c53-a83e-f3de96d41397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T06:28:28.456808Z",
     "iopub.status.busy": "2021-11-16T06:28:28.456305Z",
     "iopub.status.idle": "2021-11-16T06:28:40.115092Z",
     "shell.execute_reply": "2021-11-16T06:28:40.114512Z",
     "shell.execute_reply.started": "2021-11-16T06:28:28.456776Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-16 14:28:40,111] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - [Evaluation result] avg_acc=0.9207\n"
     ]
    }
   ],
   "source": [
    "## 使用test数据集进行预测，3epochs最优模型结果精度为89.93%，6epochs最优模型结果精度为92.07%\n",
    "result = trainer.evaluate(test_dataset, batch_size=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b7c81e-9222-4300-8fd2-f3515b3fb65e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T06:28:40.116625Z",
     "iopub.status.busy": "2021-11-16T06:28:40.116318Z",
     "iopub.status.idle": "2021-11-16T06:28:45.035844Z",
     "shell.execute_reply": "2021-11-16T06:28:45.035223Z",
     "shell.execute_reply.started": "2021-11-16T06:28:40.116599Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-16 14:28:40,122] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n",
      "[2021-11-16 14:28:44,835] [    INFO] - Loaded parameters from /home/aistudio/data/data16287/ckpt/best_model/model.pdparams\n",
      "[2021-11-16 14:28:44,842] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 昌平京基鹭府10月29日推别墅1200万套起享97折　　新浪房产讯(编辑郭彪)京基鹭府(论坛相册户型样板间点评地图搜索)售楼处位于昌平区京承高速北七家出口向西南公里路南。项目预计10月29日开盘，总价1200万元/套起，2012年年底入住。待售户型为联排户型面积为410-522平方米，独栋户型面积为938平方米，双拼户型面积为522平方米。　　京基鹭府项目位于昌平定泗路与东北路交界处。项目周边配套齐全，幼儿园：伊顿双语幼儿园、温莎双语幼儿园；中学：北师大亚太实验学校、潞河中学(北京市重点)；大学：王府语言学校、北京邮电大学、现代音乐学院；医院：王府中西医结合医院(三级甲等)、潞河医院、解放军263医院、安贞医院昌平分院；购物：龙德广场、中联万家商厦、世纪华联超市、瑰宝购物中心、家乐福超市；酒店：拉斐特城堡、鲍鱼岛；休闲娱乐设施：九华山庄、温都温泉度假村、小汤山疗养院、龙脉温泉度假村、小汤山文化广场、皇港高尔夫、高地高尔夫、北鸿高尔夫球场；银行：工商银行、建设银行、中国银行、北京农村商业银行；邮局：中国邮政储蓄；其它：北七家建材城、百安居建材超市、北七家镇武装部、北京宏翔鸿企业孵化基地等，享受便捷生活。 \n",
      "Lable: 房产\n",
      "\n",
      "Data: 尽管官方到今天也没有公布《使命召唤：现代战争2》的游戏详情，但《使命召唤：现代战争2》首部包含游戏画面的影片终于现身。虽然影片仅有短短不到20秒，但影片最后承诺大家将于美国时间5月24日NBA职业篮球东区决赛时将会揭露更多的游戏内容。　　这部只有18秒的广告片闪现了9个镜头，能够辨识的场景有直升机飞向海岛军事工事，有飞机场争夺战，有潜艇和水下工兵，有冰上乘具，以及其他的一些镜头。整体来看《现代战争2》很大可能仍旧与俄罗斯有关。　　片尾有一则预告：“May24th，EasternConferenceFinals”，这是什么？这是说当前美国NBA联赛东部总决赛的日期。原来这部视频是NBA季后赛奥兰多魔术对波士顿凯尔特人队时，TNT电视台播放的广告。 \n",
      "Lable: 游戏\n",
      "\n",
      "Data: 罗马锋王竟公然挑战两大旗帜拉涅利的球队到底错在哪　　记者张恺报道主场一球小胜副班长巴里无可吹捧，罗马占优也纯属正常，倒是托蒂罚失点球和前两号门将先后受伤(多尼以三号身份出场)更让人揪心。阵容规模扩大，反而表现不如上赛季，缺乏一流强队的色彩，这是所有球迷对罗马的印象。　　拉涅利说：“去年我们带着嫉妒之心看国米，今年我们也有了和国米同等的超级阵容，许多教练都想有罗马的球员。阵容广了，寻找队内平衡就难了，某些时段球员的互相排斥和跟从前相比的落差都正常。有好的一面，也有不好的一面，所幸，我们一直在说一支伟大的罗马，必胜的信念和够级别的阵容，我们有了。”拉涅利的总结由近一阶段困扰罗马的队内摩擦、个别球员闹意见要走人而发，本赛季技术层面强化的罗马一直没有上赛季反扑的面貌，内部变化值得球迷关注。 \n",
      "Lable: 体育\n",
      "\n",
      "Data: 新总督致力提高加拿大公立教育质量　　滑铁卢大学校长约翰斯顿先生于10月1日担任加拿大总督职务。约翰斯顿先生还曾任麦吉尔大学长，并曾在多伦多大学、女王大学和西安大略大学担任教学职位。　　约翰斯顿先生在就职演说中表示，要将加拿大建设成为一个“聪明与关爱的国度”。为实现这一目标，他提出三个支柱：支持并关爱家庭、儿童；鼓励学习与创造；提倡慈善和志愿者精神。他尤其强调要关爱并尊重教师，并通过公立教育使每个人的才智得到充分发展。 \n",
      "Lable: 教育\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 指定数据进行预测，使用保存的最佳模型\n",
    "data = [\n",
    "    # 房产\n",
    "    [\"昌平京基鹭府10月29日推别墅1200万套起享97折　　新浪房产讯(编辑郭彪)京基鹭府(论坛相册户型样板间点评地图搜索)售楼处位于昌平区京承高速北七家出口向西南公里路南。项目预计10月29日开盘，总价1200万元/套起，2012年年底入住。待售户型为联排户型面积为410-522平方米，独栋户型面积为938平方米，双拼户型面积为522平方米。　　京基鹭府项目位于昌平定泗路与东北路交界处。项目周边配套齐全，幼儿园：伊顿双语幼儿园、温莎双语幼儿园；中学：北师大亚太实验学校、潞河中学(北京市重点)；大学：王府语言学校、北京邮电大学、现代音乐学院；医院：王府中西医结合医院(三级甲等)、潞河医院、解放军263医院、安贞医院昌平分院；购物：龙德广场、中联万家商厦、世纪华联超市、瑰宝购物中心、家乐福超市；酒店：拉斐特城堡、鲍鱼岛；休闲娱乐设施：九华山庄、温都温泉度假村、小汤山疗养院、龙脉温泉度假村、小汤山文化广场、皇港高尔夫、高地高尔夫、北鸿高尔夫球场；银行：工商银行、建设银行、中国银行、北京农村商业银行；邮局：中国邮政储蓄；其它：北七家建材城、百安居建材超市、北七家镇武装部、北京宏翔鸿企业孵化基地等，享受便捷生活。\"],\n",
    "    # 游戏\n",
    "    [\"尽管官方到今天也没有公布《使命召唤：现代战争2》的游戏详情，但《使命召唤：现代战争2》首部包含游戏画面的影片终于现身。虽然影片仅有短短不到20秒，但影片最后承诺大家将于美国时间5月24日NBA职业篮球东区决赛时将会揭露更多的游戏内容。　　这部只有18秒的广告片闪现了9个镜头，能够辨识的场景有直升机飞向海岛军事工事，有飞机场争夺战，有潜艇和水下工兵，有冰上乘具，以及其他的一些镜头。整体来看《现代战争2》很大可能仍旧与俄罗斯有关。　　片尾有一则预告：“May24th，EasternConferenceFinals”，这是什么？这是说当前美国NBA联赛东部总决赛的日期。原来这部视频是NBA季后赛奥兰多魔术对波士顿凯尔特人队时，TNT电视台播放的广告。\"],\n",
    "    # 体育\n",
    "    [\"罗马锋王竟公然挑战两大旗帜拉涅利的球队到底错在哪　　记者张恺报道主场一球小胜副班长巴里无可吹捧，罗马占优也纯属正常，倒是托蒂罚失点球和前两号门将先后受伤(多尼以三号身份出场)更让人揪心。阵容规模扩大，反而表现不如上赛季，缺乏一流强队的色彩，这是所有球迷对罗马的印象。　　拉涅利说：“去年我们带着嫉妒之心看国米，今年我们也有了和国米同等的超级阵容，许多教练都想有罗马的球员。阵容广了，寻找队内平衡就难了，某些时段球员的互相排斥和跟从前相比的落差都正常。有好的一面，也有不好的一面，所幸，我们一直在说一支伟大的罗马，必胜的信念和够级别的阵容，我们有了。”拉涅利的总结由近一阶段困扰罗马的队内摩擦、个别球员闹意见要走人而发，本赛季技术层面强化的罗马一直没有上赛季反扑的面貌，内部变化值得球迷关注。\"],\n",
    "    # 教育\n",
    "    [\"新总督致力提高加拿大公立教育质量　　滑铁卢大学校长约翰斯顿先生于10月1日担任加拿大总督职务。约翰斯顿先生还曾任麦吉尔大学长，并曾在多伦多大学、女王大学和西安大略大学担任教学职位。　　约翰斯顿先生在就职演说中表示，要将加拿大建设成为一个“聪明与关爱的国度”。为实现这一目标，他提出三个支柱：支持并关爱家庭、儿童；鼓励学习与创造；提倡慈善和志愿者精神。他尤其强调要关爱并尊重教师，并通过公立教育使每个人的才智得到充分发展。\"]\n",
    "]\n",
    "\n",
    "label_list=['体育', '科技', '社会', '娱乐', '股票', '房产', '教育', '时政', '财经', '星座', '游戏', '家居', '彩票', '时尚']\n",
    "label_map = { \n",
    "    idx: label_text for idx, label_text in enumerate(label_list)\n",
    "}\n",
    "\n",
    "model = hub.Module(\n",
    "    name='ernie',\n",
    "    task='seq-cls',\n",
    "    load_checkpoint='./ckpt/best_model/model.pdparams',\n",
    "    label_map=label_map)\n",
    "results = model.predict(data, max_seq_len=128, batch_size=1, use_gpu=True)\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\nLable: {}\\n'.format(text[0], results[idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
